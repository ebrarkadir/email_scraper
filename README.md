# ğŸ“§ Email Scraper (Python)  
TarayÄ±cÄ± gibi davranan, domain dÄ±ÅŸÄ±na Ã§Ä±kmayan, sade ama etkili bir e-posta bulucu.

Bu script, belirttiÄŸiniz bir web sitesinde gezerek sayfalardaki geÃ§erli e-posta adreslerini toplar. Sadece aynÄ± domain altÄ±ndaki baÄŸlantÄ±lara tÄ±rmanÄ±r, her sayfayÄ± bir kez ziyaret eder ve isteÄŸe baÄŸlÄ± olarak verileri dosyaya kaydeder. TarayÄ±cÄ± gibi gÃ¶rÃ¼nmek iÃ§in User-Agent desteÄŸi iÃ§erir.

---

## âœ¨ Ã–zellikler

- ğŸ” E-posta adreslerini HTML iÃ§inden tespit eder (regex)
- ğŸŒ Sadece aynÄ± domain altÄ±nda tarama yapar (dÄ±ÅŸ linkleri filtreler)
- ğŸ§­ GeniÅŸlik Ã¶ncelikli baÄŸlantÄ± taramasÄ± (deque ile BFS)
- ğŸ§  Gereksiz tekrarlarÄ± engeller (visited URL takibi)
- ğŸ›¡ï¸ User-Agent desteÄŸi ile engellemeleri aÅŸar (tarayÄ±cÄ± gibi gÃ¶rÃ¼nÃ¼r)
- ğŸ’¾ SonuÃ§larÄ± `emails.txt` olarak kaydetme seÃ§eneÄŸi

---

## ğŸ§  NasÄ±l Ã‡alÄ±ÅŸÄ±r?

1. Sizden bir baÅŸlangÄ±Ã§ URLâ€™si ister.  
2. Bu sayfaya GET isteÄŸi gÃ¶nderir (`requests`).
3. HTML iÃ§eriÄŸi `BeautifulSoup` ile parse edilir.
4. E-posta adresleri regex ile aranÄ±r.
5. Sayfadaki `<a href="...">` baÄŸlantÄ±larÄ± bulunur.
6. Sadece aynÄ± domain iÃ§indeki sayfalar `deque` kuyruÄŸuna eklenir.
7. Kuyruktaki her URL teker teker gezilir (maks. 100 sayfa).
8. Bulunan tÃ¼m e-posta adresleri terminale yazÄ±lÄ±r, isterseniz `.txt` olarak da kaydedilir.

---

## âš™ï¸ KullanÄ±lan Teknolojiler

| KÃ¼tÃ¼phane      | Ne iÅŸe yarÄ±yor?                               |
|----------------|------------------------------------------------|
| `requests`     | Sayfaya HTTP isteÄŸi gÃ¶nderir                   |
| `bs4` (BeautifulSoup) | HTML iÃ§eriÄŸini parÃ§alar, baÄŸlantÄ±larÄ± bulur  |
| `re`           | E-posta desenini bulmak iÃ§in regex kullanÄ±lÄ±r |
| `urllib.parse` | URL birleÅŸtirme ve domain kontrolÃ¼ yapar       |
| `collections.deque` | BaÄŸlantÄ±larÄ± sÄ±rayla gezmek iÃ§in kullanÄ±lÄ±r (FIFO) |

---

## ğŸ›¡ï¸ User-Agent Nedir, Neden KullanÄ±lÄ±r?

BazÄ± web siteleri Python gibi botlardan gelen istekleri engelleyebilir. Bunu anlamak iÃ§in HTTP isteÄŸi iÃ§inde gÃ¶nderilen `User-Agent` bilgisine bakarlar.

Bu scraper, User-Agent headerâ€™Ä± ekleyerek kendini bir tarayÄ±cÄ± gibi tanÄ±tÄ±r:

```http
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/114.0.0.0 Safari/537.36
```

## ğŸš€ KullanÄ±m

### 1. Projeyi GitHub Ã¼zerinden klonlayÄ±n
```
git clone https://github.com/kullanici/email-scraper.git
```

### 2. Proje klasÃ¶rÃ¼ne geÃ§in
```
cd email-scraper
```

### 3. Gerekli Python kÃ¼tÃ¼phanelerini yÃ¼kleyin
```
pip install requests beautifulsoup4 lxml
```

### 4. Script'i Ã§alÄ±ÅŸtÄ±rÄ±n
```
python3 email_scraper.py
```


